<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Reference Architecture &mdash; Fuel for OpenStack 3.0 documentation</title>
    
    <link rel="stylesheet" href="../_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '3.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="Fuel for OpenStack 3.0 documentation" href="../index.html" />
    <link rel="next" title="Create a multi-node OpenStack cluster using Fuel Web" href="0045-installation-fuel-web.html" />
    <link rel="prev" title="Introduction" href="0020-introduction.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="0045-installation-fuel-web.html" title="Create a multi-node OpenStack cluster using Fuel Web"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="0020-introduction.html" title="Introduction"
             accesskey="P">previous</a> |</li>
        <li><a href="../index.html">Fuel for OpenStack 3.0 documentation</a> &raquo;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Reference Architecture</a><ul>
<li><a class="reference internal" href="#overview">Overview</a><ul>
<li><a class="reference internal" href="#single-node-deployment">Single node deployment</a></li>
<li><a class="reference internal" href="#multi-node-non-ha-deployment-compact-swift">Multi-node (non-HA) deployment (compact Swift)</a></li>
<li><a class="reference internal" href="#multi-node-non-ha-deployment-standalone-swift">Multi-node (non-HA) deployment (standalone Swift)</a></li>
<li><a class="reference internal" href="#multi-node-ha-deployment-compact">Multi-node (HA) deployment (Compact)</a></li>
<li><a class="reference internal" href="#multi-node-ha-deployment-compact-neutron">Multi-node (HA) deployment (Compact Neutron)</a></li>
<li><a class="reference internal" href="#multi-node-ha-deployment-standalone">Multi-node (HA) deployment (Standalone)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#a-closer-look-at-the-multi-node-ha-compact-deployment">A closer look at the Multi-node (HA) Compact deployment</a><ul>
<li><a class="reference internal" href="#logical-setup">Logical Setup</a><ul>
<li><a class="reference internal" href="#controller-nodes">Controller Nodes</a></li>
<li><a class="reference internal" href="#compute-nodes">Compute Nodes</a></li>
<li><a class="reference internal" href="#storage-nodes">Storage Nodes</a></li>
</ul>
</li>
<li><a class="reference internal" href="#cluster-sizing">Cluster Sizing</a></li>
<li><a class="reference internal" href="#network-architecture">Network Architecture</a><ul>
<li><a class="reference internal" href="#public-network">Public Network</a></li>
<li><a class="reference internal" href="#internal-management-network">Internal (Management) Network</a></li>
<li><a class="reference internal" href="#private-network">Private Network</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#technical-considerations">Technical Considerations</a><ul>
<li><a class="reference internal" href="#neutron-vs-nova-network">Neutron vs. nova-network</a></li>
<li><a class="reference internal" href="#cinder-vs-nova-volume">Cinder vs. nova-volume</a></li>
<li><a class="reference internal" href="#swift-object-storage-notes">Swift (object storage) notes</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="0020-introduction.html"
                        title="previous chapter">Introduction</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="0045-installation-fuel-web.html"
                        title="next chapter">Create a multi-node OpenStack cluster using Fuel Web</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="../_sources/pages/0040-reference-architecture.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="reference-architecture">
<span id="reference-archiecture"></span><h1>Reference Architecture<a class="headerlink" href="#reference-architecture" title="Permalink to this headline">¶</a></h1>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><a class="reference internal" href="#overview" id="id1">Overview</a><ul>
<li><a class="reference internal" href="#single-node-deployment" id="id2">Single node deployment</a></li>
<li><a class="reference internal" href="#multi-node-non-ha-deployment-compact-swift" id="id3">Multi-node (non-HA) deployment (compact Swift)</a></li>
<li><a class="reference internal" href="#multi-node-non-ha-deployment-standalone-swift" id="id4">Multi-node (non-HA) deployment (standalone Swift)</a></li>
<li><a class="reference internal" href="#multi-node-ha-deployment-compact" id="id5">Multi-node (HA) deployment (Compact)</a></li>
<li><a class="reference internal" href="#multi-node-ha-deployment-compact-neutron" id="id6">Multi-node (HA) deployment (Compact Neutron)</a></li>
<li><a class="reference internal" href="#multi-node-ha-deployment-standalone" id="id7">Multi-node (HA) deployment (Standalone)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#a-closer-look-at-the-multi-node-ha-compact-deployment" id="id8">A closer look at the Multi-node (HA) Compact deployment</a><ul>
<li><a class="reference internal" href="#logical-setup" id="id9">Logical Setup</a><ul>
<li><a class="reference internal" href="#controller-nodes" id="id10">Controller Nodes</a></li>
<li><a class="reference internal" href="#compute-nodes" id="id11">Compute Nodes</a></li>
<li><a class="reference internal" href="#storage-nodes" id="id12">Storage Nodes</a></li>
</ul>
</li>
<li><a class="reference internal" href="#cluster-sizing" id="id13">Cluster Sizing</a></li>
<li><a class="reference internal" href="#network-architecture" id="id14">Network Architecture</a><ul>
<li><a class="reference internal" href="#public-network" id="id15">Public Network</a></li>
<li><a class="reference internal" href="#internal-management-network" id="id16">Internal (Management) Network</a></li>
<li><a class="reference internal" href="#private-network" id="id17">Private Network</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#technical-considerations" id="id18">Technical Considerations</a><ul>
<li><a class="reference internal" href="#neutron-vs-nova-network" id="id19">Neutron vs. nova-network</a></li>
<li><a class="reference internal" href="#cinder-vs-nova-volume" id="id20">Cinder vs. nova-volume</a></li>
<li><a class="reference internal" href="#swift-object-storage-notes" id="id21">Swift (object storage) notes</a></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="overview">
<h2><a class="toc-backref" href="#id1">Overview</a><a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>Before you install any hardware or software, you must know what it is
you&#8217;re trying to achieve. This section looks at the basic components of
an OpenStack infrastructure and organizes them into one of the more
common reference architectures. You&#8217;ll then use that architecture as a
basis for installing OpenStack in the next section.</p>
<p>As you know, OpenStack provides the following basic services:</p>
<blockquote>
<div><ul>
<li><p class="first"><strong>Compute</strong>: Compute servers are the workhorses of your installation; they&#8217;re the servers on which your users&#8217; virtual machines are created. <cite>Nova-scheduler</cite> controls the life-cycle of these VMs.</p>
</li>
<li><p class="first"><strong>Networking</strong>: Because an OpenStack cluster (virtually) always includes multiple servers, the ability for them to communicate with each other and with the outside world is crucial. Networking was originally handled by the <cite>Nova-network</cite> service, but it has given way to the newer Neutron (formerly Quantum) networking service. Authentication and authorization for these transactions are handled by <cite>Keystone</cite>.</p>
</li>
<li><p class="first"><strong>Storage</strong>: OpenStack provides for two different types of storage: block storage and object storage. Block storage is traditional data storage, with small, fixed-size blocks that are mapped to locations on storage media. At its simplest level, OpenStack provides block storage using <cite>nova-volume</cite>, but it is common to use <cite>Cinder</cite>.</p>
<p>Object storage, on the other hand, consists of single variable-size objects that are described by system-level metadata, and you can access this capability using <cite>Swift</cite>.</p>
<p>OpenStack storage is used for your users&#8217; objects, but it is also used for storing the images used to create new VMs. This capability is handled by <cite>Glance</cite>.</p>
</li>
</ul>
</div></blockquote>
<p>These services can be combined in many different ways. Out of the box,
Fuel supports the following deployment configurations:</p>
<div class="section" id="single-node-deployment">
<h3><a class="toc-backref" href="#id2">Single node deployment</a><a class="headerlink" href="#single-node-deployment" title="Permalink to this headline">¶</a></h3>
<p>In a production environment, you will never have a single-node
deployment of OpenStack, partly because it forces you to make a number
of compromises as to the number and types of services that you can
deploy. It is, however, extremely useful if you just want to see how
OpenStack works from a user&#8217;s point of view. In this case, all of the
essential services run out of a single server:</p>
<img alt="https://docs.google.com/drawings/d/1gGNYYayPAPPHgOYi98Dmebry4hP1SOGF2APXWzbnNo8/pub?w=767&amp;h=413" src="https://docs.google.com/drawings/d/1gGNYYayPAPPHgOYi98Dmebry4hP1SOGF2APXWzbnNo8/pub?w=767&amp;h=413" />
</div>
<div class="section" id="multi-node-non-ha-deployment-compact-swift">
<h3><a class="toc-backref" href="#id3">Multi-node (non-HA) deployment (compact Swift)</a><a class="headerlink" href="#multi-node-non-ha-deployment-compact-swift" title="Permalink to this headline">¶</a></h3>
<p>More commonly, your OpenStack installation will consist of multiple
servers. Exactly how many is up to you, of course, but the main idea
is that your controller(s) are separate from your compute servers, on
which your users&#8217; VMs will actually run. One arrangement that will
enable you to achieve this separation while still keeping your
hardware investment relatively modest is to house your storage on your
controller nodes.</p>
</div>
<div class="section" id="multi-node-non-ha-deployment-standalone-swift">
<h3><a class="toc-backref" href="#id4">Multi-node (non-HA) deployment (standalone Swift)</a><a class="headerlink" href="#multi-node-non-ha-deployment-standalone-swift" title="Permalink to this headline">¶</a></h3>
<p>A more common arrangement is to provide separate servers for storage.
This has the advantage of reducing the number of controllers you must
provide; because Swift runs on its own servers, you can reduce the
number of controllers from three (or five, for a full Swift implementation) to one, if desired:</p>
<img alt="https://docs.google.com/drawings/d/1nVEtfpNLaLV4EBKJQleLxovqMVrDCRT7yFWTYUQASB0/pub?w=767&amp;h=413" src="https://docs.google.com/drawings/d/1nVEtfpNLaLV4EBKJQleLxovqMVrDCRT7yFWTYUQASB0/pub?w=767&amp;h=413" />
</div>
<div class="section" id="multi-node-ha-deployment-compact">
<h3><a class="toc-backref" href="#id5">Multi-node (HA) deployment (Compact)</a><a class="headerlink" href="#multi-node-ha-deployment-compact" title="Permalink to this headline">¶</a></h3>
<p>Production environments typically require high availability, which
involves several architectural requirements. Specifically, you will
need at least three controllers, and
certain components will be deployed in multiple locations to prevent
single points of failure. That&#8217;s not to say, however, that you can&#8217;t
reduce hardware requirements by combining your storage, network, and controller
nodes:</p>
<img alt="https://docs.google.com/drawings/d/1xLv4zog19j0MThVGV9gSYa4wh1Ma4MQYsBz-4vE1xvg/pub?w=767&amp;h=413" src="https://docs.google.com/drawings/d/1xLv4zog19j0MThVGV9gSYa4wh1Ma4MQYsBz-4vE1xvg/pub?w=767&amp;h=413" />
</div>
<div class="section" id="multi-node-ha-deployment-compact-neutron">
<h3><a class="toc-backref" href="#id6">Multi-node (HA) deployment (Compact Neutron)</a><a class="headerlink" href="#multi-node-ha-deployment-compact-neutron" title="Permalink to this headline">¶</a></h3>
<p>Another way you can add functionality to your cluster without
increasing hardware requirements is to install Quantum on your
controller nodes. This architecture still provides high availability,
but avoids the need for a separate Neutron node:</p>
<img alt="https://docs.google.com/drawings/d/1GYNM5yTJSlZe9nB5SHnlrqyMfVRdVh02OFLwXlz-itc/pub?w=767&amp;h=413" src="https://docs.google.com/drawings/d/1GYNM5yTJSlZe9nB5SHnlrqyMfVRdVh02OFLwXlz-itc/pub?w=767&amp;h=413" />
</div>
<div class="section" id="multi-node-ha-deployment-standalone">
<h3><a class="toc-backref" href="#id7">Multi-node (HA) deployment (Standalone)</a><a class="headerlink" href="#multi-node-ha-deployment-standalone" title="Permalink to this headline">¶</a></h3>
<p>For larger production deployments, its more common to provide
dedicated hardware for storage and networking. This architecture still
gives you the advantages of high availability, but this clean
separation makes your cluster more maintainable by separating storage,
networking, and controller functionality:</p>
<img alt="https://docs.google.com/drawings/d/1rJEZi5-l9oemMmrkH5UPjitQQDVGuZQ1KS0pPWTuovY/pub?w=769&amp;h=594" src="https://docs.google.com/drawings/d/1rJEZi5-l9oemMmrkH5UPjitQQDVGuZQ1KS0pPWTuovY/pub?w=769&amp;h=594" />
<p>Where Fuel really shines is in the creation of more complex
architectures, so in this document you&#8217;ll learn how to use Fuel to
easily create a multi-node HA OpenStack cluster. To reduce the amount
of hardware you&#8217;ll need to follow the installation in section 3,
however, the guide focuses on the Multi-node HA Compact
architecture.</p>
<p>Lets take a closer look at the details of this deployment configuration.</p>
</div>
</div>
<div class="section" id="a-closer-look-at-the-multi-node-ha-compact-deployment">
<h2><a class="toc-backref" href="#id8">A closer look at the Multi-node (HA) Compact deployment</a><a class="headerlink" href="#a-closer-look-at-the-multi-node-ha-compact-deployment" title="Permalink to this headline">¶</a></h2>
<p>In this section, you&#8217;ll learn more about the Multi-node (HA) Compact
deployment configuration and how it achieves high availability in preparation
for installing this cluster in section 3. As you may recall, this
configuration looks something like this:</p>
<img alt="https://docs.google.com/drawings/d/1xLv4zog19j0MThVGV9gSYa4wh1Ma4MQYsBz-4vE1xvg/pub?w=767&amp;h=413" src="https://docs.google.com/drawings/d/1xLv4zog19j0MThVGV9gSYa4wh1Ma4MQYsBz-4vE1xvg/pub?w=767&amp;h=413" />
<p>OpenStack services are interconnected by RESTful HTTP-based APIs and
AMQP-based RPC messages. So redundancy for stateless OpenStack API
services is implemented through the combination of Virtual IP (VIP)
management using keepalived and load balancing using HAProxy. Stateful
OpenStack components, such as the state database and messaging server,
rely on their respective active/active modes for high availability.
For example, RabbitMQ uses built-in clustering capabilities, while the
database uses MySQL/Galera replication.</p>
<img alt="https://docs.google.com/drawings/pub?id=1PzRBUaZEPMG25488mlb42fRdlFS3BygPwbAGBHudnTM&amp;w=750&amp;h=491" src="https://docs.google.com/drawings/pub?id=1PzRBUaZEPMG25488mlb42fRdlFS3BygPwbAGBHudnTM&amp;w=750&amp;h=491" />
<p>Lets take a closer look at what an OpenStack deployment looks like, and
what it will take to achieve high availability for an OpenStack
deployment.</p>
<div class="section" id="logical-setup">
<h3><a class="toc-backref" href="#id9">Logical Setup</a><a class="headerlink" href="#logical-setup" title="Permalink to this headline">¶</a></h3>
<p>An OpenStack HA cluster involves, at a minimum, three types of nodes:
controller nodes, compute nodes, and storage nodes.</p>
<div class="section" id="controller-nodes">
<h4><a class="toc-backref" href="#id10">Controller Nodes</a><a class="headerlink" href="#controller-nodes" title="Permalink to this headline">¶</a></h4>
<p>The first order of business in achieving high availability (HA) is
redundancy, so the first step is to provide multiple controller nodes.
You must keep in mind, however, that the database uses Galera to
achieve HA, and Galera is a quorum-based system. That means that you must provide at least 3
controller nodes.</p>
<img alt="https://docs.google.com/drawings/pub?id=1aftE8Yes7CdVSZgZD1A82T_2GqL2SMImtRYU914IMyQ&amp;w=869&amp;h=855" src="https://docs.google.com/drawings/pub?id=1aftE8Yes7CdVSZgZD1A82T_2GqL2SMImtRYU914IMyQ&amp;w=869&amp;h=855" />
<p>Every OpenStack controller runs keepalived, which manages a single
Virtual IP (VIP) for all controller nodes, and HAProxy, which manages
HTTP and TCP load balancing of requests going to OpenStack API
services, RabbitMQ, and MySQL.</p>
<p>When an end user accesses the OpenStack cloud using Horizon or makes a
request to the REST API for services such as nova-api, glance-api,
keystone-api, quantum-api, nova-scheduler, MySQL or RabbitMQ, the
request goes to the live controller node currently holding the VIP,
and the connection gets terminated by HAProxy. When the next request
comes in, HAProxy handles it, and may send it to the original
controller or another in the cluster, depending on load conditions.</p>
<p>Each of the services housed on the controller nodes has its own
mechanism for achieving HA:</p>
<ul class="simple">
<li>nova-api, glance-api, keystone-api, quantum-api and nova-scheduler are stateless services that do not require any special attention besides load balancing.</li>
<li>Horizon, as a typical web application, requires sticky sessions to be enabled at the load balancer.</li>
<li>RabbitMQ provides active/active high availability using mirrored queues.</li>
<li>MySQL high availability is achieved through Galera active/active multi-master deployment.</li>
</ul>
</div>
<div class="section" id="compute-nodes">
<h4><a class="toc-backref" href="#id11">Compute Nodes</a><a class="headerlink" href="#compute-nodes" title="Permalink to this headline">¶</a></h4>
<p>OpenStack compute nodes are, in many ways, the foundation of your
cluster; they are the servers on which your users will create their
Virtual Machines (VMs) and host their applications. Compute nodes need
to talk to controller nodes and reach out to essential services such
as RabbitMQ and MySQL. They use the same approach that provides
redundancy to the end-users of Horizon and REST APIs, reaching out to
controller nodes using the VIP and going through HAProxy.</p>
<img alt="https://docs.google.com/drawings/pub?id=16gsjc81Ptb5SL090XYAN8Kunrxfg6lScNCo3aReqdJI&amp;w=873&amp;h=801" src="https://docs.google.com/drawings/pub?id=16gsjc81Ptb5SL090XYAN8Kunrxfg6lScNCo3aReqdJI&amp;w=873&amp;h=801" />
</div>
<div class="section" id="storage-nodes">
<h4><a class="toc-backref" href="#id12">Storage Nodes</a><a class="headerlink" href="#storage-nodes" title="Permalink to this headline">¶</a></h4>
<p>In this OpenStack cluster reference architecture, shared storage acts
as a backend for Glance, so that multiple Glance instances running on
controller nodes can store images and retrieve images from it. To
achieve this, you are going to deploy Swift. This enables you to use
it not only for storing VM images, but also for any other objects such
as user files.</p>
<img alt="https://docs.google.com/drawings/pub?id=1Xd70yy7h5Jq2oBJ12fjnPWP8eNsWilC-ES1ZVTFo0m8&amp;w=777&amp;h=778" src="https://docs.google.com/drawings/pub?id=1Xd70yy7h5Jq2oBJ12fjnPWP8eNsWilC-ES1ZVTFo0m8&amp;w=777&amp;h=778" />
</div>
</div>
<div class="section" id="cluster-sizing">
<h3><a class="toc-backref" href="#id13">Cluster Sizing</a><a class="headerlink" href="#cluster-sizing" title="Permalink to this headline">¶</a></h3>
<p>This reference architecture is well suited for production-grade
OpenStack deployments on a medium and large scale when you can afford
allocating several servers for your OpenStack controller nodes in
order to build a fully redundant and highly available environment.</p>
<p>The absolute minimum requirement for a highly-available OpenStack
deployment is to allocate 4 nodes:</p>
<ul class="simple">
<li>3 controller nodes, combined with storage</li>
<li>1 compute node</li>
</ul>
<img alt="https://docs.google.com/drawings/pub?id=19Dk1qD5V50-N0KX4kdG_0EhGUBP7D_kLi2dU6caL9AM&amp;w=767&amp;h=413" src="https://docs.google.com/drawings/pub?id=19Dk1qD5V50-N0KX4kdG_0EhGUBP7D_kLi2dU6caL9AM&amp;w=767&amp;h=413" />
<p>If you want to run storage separately from the controllers, you can do that as well by raising the bar to 7 nodes:</p>
<ul class="simple">
<li>3 controller nodes</li>
<li>3 storage nodes</li>
<li>1 compute node</li>
</ul>
<img alt="https://docs.google.com/drawings/pub?id=1xmGUrk2U-YWmtoS77xqG0tzO3A47p6cI3mMbzLKG8tY&amp;w=769&amp;h=594" src="https://docs.google.com/drawings/pub?id=1xmGUrk2U-YWmtoS77xqG0tzO3A47p6cI3mMbzLKG8tY&amp;w=769&amp;h=594" />
<p>Of course, you are free to choose how to deploy OpenStack based on the
amount of available hardware and on your goals (such as whether you
want a compute-oriented or storage-oriented cluster).</p>
<p>For a typical OpenStack compute deployment, you can use this table as
high-level guidance to determine the number of controllers, compute,
and storage nodes you should have:</p>
<table border="1" class="docutils">
<colgroup>
<col width="29%" />
<col width="24%" />
<col width="16%" />
<col width="31%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"># of Machines</th>
<th class="head">Controllers</th>
<th class="head">Compute</th>
<th class="head">Storage</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>4-10</td>
<td>3</td>
<td>1-7</td>
<td>on controllers</td>
</tr>
<tr class="row-odd"><td>11-40</td>
<td>3</td>
<td>5-34</td>
<td>3 (separate)</td>
</tr>
<tr class="row-even"><td>41-100</td>
<td>4</td>
<td>31-90</td>
<td>6 (separate)</td>
</tr>
<tr class="row-odd"><td>&gt;100</td>
<td>5</td>
<td>&gt;86</td>
<td>9 (separate)</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="network-architecture">
<h3><a class="toc-backref" href="#id14">Network Architecture</a><a class="headerlink" href="#network-architecture" title="Permalink to this headline">¶</a></h3>
<p>The current architecture assumes the presence of 3 NIC cards in hardware, but can be customized two or more NICs. Most servers come with at least two network interfaces. In this case, let&#8217;s consider a typical example of three NIC cards. They&#8217;re utilized as follows:</p>
<ul class="simple">
<li><strong>eth0</strong>: the internal management network, used for communication with Puppet &amp; Cobbler</li>
<li><strong>eth1</strong>: the public network, and floating IPs assigned to VMs</li>
<li><strong>eth2</strong>: the private network, for communication between OpenStack VMs, and the bridge interface (VLANs)</li>
</ul>
<p>In the multi-host networking mode, you can choose between the FlatDHCPManager and VlanManager network managers in OpenStack. The figure below illustrates the relevant nodes and networks.</p>
<img alt="https://docs.google.com/drawings/pub?id=11KtrvPxqK3ilkAfKPSVN5KzBjnSPIJw-jRDc9fiYhxw&amp;w=810&amp;h=1060" src="https://docs.google.com/drawings/pub?id=11KtrvPxqK3ilkAfKPSVN5KzBjnSPIJw-jRDc9fiYhxw&amp;w=810&amp;h=1060" />
<p>Lets take a closer look at each network and how its used within the cluster.</p>
<div class="section" id="public-network">
<h4><a class="toc-backref" href="#id15">Public Network</a><a class="headerlink" href="#public-network" title="Permalink to this headline">¶</a></h4>
<p>This network allows inbound connections to VMs from the outside world (allowing users to connect to VMs from the Internet). It also allows outbound connections from VMs to the outside world.</p>
<p>For security reasons, the public network is usually isolated from the private network and internal (management) network. Typically, it&#8217;s a single C class network from your globally routed or private network range.</p>
<p>To enable Internet access to VMs, the public network provides the address space for the floating IPs assigned to individual VM instances by the project administrator. Nova-network or Neutron (formerly Quantum) services can then configure this address on the public network interface of the Network controller node. If the cluster uses nova-network, nova- network uses iptables to create a Destination NAT from this address to the fixed IP of the corresponding VM instance through the appropriate virtual bridge interface on the Network controller node.</p>
<p>In the other direction, the public network provides connectivity to the globally routed address space for VMs. The IP address from the public network that has been assigned to a compute node is used as the source for the Source NAT performed for traffic going from VM instances on the compute node to Internet.</p>
<p>The public network also provides VIPs for Endpoint nodes, which are used to connect to OpenStack services APIs.</p>
</div>
<div class="section" id="internal-management-network">
<h4><a class="toc-backref" href="#id16">Internal (Management) Network</a><a class="headerlink" href="#internal-management-network" title="Permalink to this headline">¶</a></h4>
<p>The internal network connects all OpenStack nodes in the cluster. All components of an OpenStack cluster communicate with each other using this network. This network must be isolated from both the private and public networks for security reasons.</p>
<p>The internal network can also be used for serving iSCSI protocol exchanges between Compute and Storage nodes.</p>
<p>This network usually is a single C class network from your private, non-globally routed IP address range.</p>
</div>
<div class="section" id="private-network">
<h4><a class="toc-backref" href="#id17">Private Network</a><a class="headerlink" href="#private-network" title="Permalink to this headline">¶</a></h4>
<p>The private network facilitates communication between each tenant&#8217;s VMs. Private network address spaces are part of the enterprise network address space. Fixed IPs of virtual instances are directly accessible from the rest of Enterprise network.</p>
<p>The private network can be segmented into separate isolated VLANs, which are managed by nova-network or Neutron (formerly Quantum) services.</p>
</div>
</div>
</div>
<div class="section" id="technical-considerations">
<h2><a class="toc-backref" href="#id18">Technical Considerations</a><a class="headerlink" href="#technical-considerations" title="Permalink to this headline">¶</a></h2>
<p>Before performing any installations, you&#8217;ll need to make a number of
decisions about which services to deploy, but from a general
architectural perspective, it&#8217;s important to think about how you want
to handle both networking and block storage.</p>
<div class="section" id="neutron-vs-nova-network">
<h3><a class="toc-backref" href="#id19">Neutron vs. nova-network</a><a class="headerlink" href="#neutron-vs-nova-network" title="Permalink to this headline">¶</a></h3>
<p>Neutron (formerly Quantum) is a service which provides networking-as-a-service functionality in OpenStack. It has a rich tenant-facing API for defining network connectivity and addressing in the cloud, and gives operators the ability to leverage different networking technologies to power their cloud networking.</p>
<p>There are various deployment use cases for Neutron. Fuel supports the most common of them, called Provider Router with Private Networks. It provides each tenant with one or more private networks, which can communicate with the outside world via a Neutron router.</p>
<p>Neutron is not, however, required in order to run an OpenStack cluster; if you don&#8217;t need (or want) this added functionality, it&#8217;s perfectly acceptable to continue using nova-network.</p>
<p>In order to deploy Neutron, you need to enable it in the Fuel configuration. Fuel will then set up an additional node in the OpenStack installation to act as an L3 router, or, depending on the configuration options you&#8217;ve chosen, install Neutron on the controllers.</p>
</div>
<div class="section" id="cinder-vs-nova-volume">
<h3><a class="toc-backref" href="#id20">Cinder vs. nova-volume</a><a class="headerlink" href="#cinder-vs-nova-volume" title="Permalink to this headline">¶</a></h3>
<p>Cinder is a persistent storage management service, also known as block-storage-as-a-service. It was created to replace nova-volume, and
provides persistent storage for VMs.</p>
<p>If you decide use Cinder for persistent storage, you will need to both
enable Cinder and create the block devices on which it will store data.
You will then provide information about those blocks devices during the Fuel
install. (You&#8217;ll see an example how to do this in section 3.)</p>
<p>Cinder block devices can be:</p>
<ul class="simple">
<li>created by Cobbler during the initial node installation, or</li>
<li>attached manually (e.g. as additional virtual disks if you are using VirtualBox, or as additional physical RAID, SAN volumes)</li>
</ul>
</div>
<div class="section" id="swift-object-storage-notes">
<span id="swift-and-object-storage-notes"></span><h3><a class="toc-backref" href="#id21">Swift (object storage) notes</a><a class="headerlink" href="#swift-object-storage-notes" title="Permalink to this headline">¶</a></h3>
<p>FUEL currently supports several ways to deploy the swift service:</p>
<ul>
<li><p class="first">Swift absent</p>
<p>By default, Glance uses the filesystem backend to store virtual machine images. In this case, you can use any of shared file systems Glance supports.</p>
</li>
<li><p class="first">Swift compact</p>
<p>In this mode the role of swift-storage and swift-proxy are combined with a nova-controller. Use it only for testing in order to save nodes; it&#8217;s not suitable for production.</p>
</li>
<li><p class="first">Swift standalone</p>
<p>In this case the Proxy service and Storage (account/container/object) services reside on separate nodes, with one proxy node and a minimum of three storage nodes.  (For a production cluster, a minimum of five nodes is recommended.)</p>
</li>
</ul>
<p>Now let&#8217;s look at performing an actual OpenStack installation using Fuel.</p>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="0045-installation-fuel-web.html" title="Create a multi-node OpenStack cluster using Fuel Web"
             >next</a> |</li>
        <li class="right" >
          <a href="0020-introduction.html" title="Introduction"
             >previous</a> |</li>
        <li><a href="../index.html">Fuel for OpenStack 3.0 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2013, Mirantis.
      Last updated on 2013/07/22.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2b1.
    </div>
  </body>
</html>