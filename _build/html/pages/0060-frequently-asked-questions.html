<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>FAQ (Frequently Asked Questions) &mdash; Fuel for OpenStack 3.0 documentation</title>
    
    <link rel="stylesheet" href="../_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '3.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="Fuel for OpenStack 3.0 documentation" href="../index.html" />
    <link rel="prev" title="Production Considerations" href="0055-production-considerations.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="0055-production-considerations.html" title="Production Considerations"
             accesskey="P">previous</a> |</li>
        <li><a href="../index.html">Fuel for OpenStack 3.0 documentation</a> &raquo;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">FAQ (Frequently Asked Questions)</a><ul>
<li><a class="reference internal" href="#known-issues-and-workarounds">Known Issues and Workarounds</a><ul>
<li><a class="reference internal" href="#rabbitmq-cluster-restart-issues-following-a-systemwide-failure">RabbitMQ Cluster Restart Issues Following A Systemwide Failure</a></li>
<li><a class="reference internal" href="#id1">Galera cluster has no built-in restart or shutdown mechanism</a></li>
<li><a class="reference internal" href="#id2">Useful links</a></li>
</ul>
</li>
<li><a class="reference internal" href="#common-technical-issues">Common Technical Issues</a><ul>
<li><a class="reference internal" href="#creating-the-xfs-partition">Creating the XFS partition</a></li>
<li><a class="reference internal" href="#redeploying-a-node-from-scratch">Redeploying a node from scratch</a></li>
</ul>
</li>
<li><a class="reference internal" href="#other-questions">Other Questions</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="0055-production-considerations.html"
                        title="previous chapter">Production Considerations</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="../_sources/pages/0060-frequently-asked-questions.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="faq-frequently-asked-questions">
<span id="faq"></span><h1>FAQ (Frequently Asked Questions)<a class="headerlink" href="#faq-frequently-asked-questions" title="Permalink to this headline">¶</a></h1>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><a class="reference internal" href="#known-issues-and-workarounds" id="id4">Known Issues and Workarounds</a><ul>
<li><a class="reference internal" href="#rabbitmq-cluster-restart-issues-following-a-systemwide-failure" id="id5">RabbitMQ Cluster Restart Issues Following A Systemwide Failure</a></li>
<li><a class="reference internal" href="#id1" id="id6">Galera cluster has no built-in restart or shutdown mechanism</a></li>
<li><a class="reference internal" href="#id2" id="id7">Useful links</a></li>
</ul>
</li>
<li><a class="reference internal" href="#common-technical-issues" id="id8">Common Technical Issues</a><ul>
<li><a class="reference internal" href="#creating-the-xfs-partition" id="id9">Creating the XFS partition</a></li>
<li><a class="reference internal" href="#redeploying-a-node-from-scratch" id="id10">Redeploying a node from scratch</a></li>
</ul>
</li>
<li><a class="reference internal" href="#other-questions" id="id11">Other Questions</a></li>
</ul>
</div>
<div class="section" id="known-issues-and-workarounds">
<h2><a class="toc-backref" href="#id4">Known Issues and Workarounds</a><a class="headerlink" href="#known-issues-and-workarounds" title="Permalink to this headline">¶</a></h2>
<div class="section" id="rabbitmq-cluster-restart-issues-following-a-systemwide-failure">
<h3><a class="toc-backref" href="#id5">RabbitMQ Cluster Restart Issues Following A Systemwide Failure</a><a class="headerlink" href="#rabbitmq-cluster-restart-issues-following-a-systemwide-failure" title="Permalink to this headline">¶</a></h3>
<p><strong>Issue:</strong>
As a rule of thumb, all RabbitMQ nodes must not be shut down simultaneously. RabbitMQ requires that after a full shutdown of the cluster, the first node brought up should be the last one to shut down, but it&#8217;s not always possible to know which node that is in the event of a power outage or similar event.  Versions 2.1 and later of Fuel solve this problem by managing the restart of available nodes, so you should not experience difficulty with this issue.</p>
<p>If you are still using previous versions of Fuel, the following describes how Fuel 2.1 works around this problem which, in turn, you can use to perform the steps manually.</p>
<p><strong>Workaround:</strong>
There are 2 possible scenarios, depending on the results of the shutdown:</p>
<blockquote>
<div><ol class="arabic simple">
<li>The RabbitMQ master node is alive and can be started.</li>
<li>It&#8217;s impossible to start the RabbitMQ master node due to a hardware or system failure</li>
</ol>
</div></blockquote>
<p>Fuel 2.1 updates the <tt class="docutils literal"><span class="pre">/etc/init.d/rabbitmq-server</span></tt> init scripts for RHEL/Centos and Ubuntu to customized versions. These scripts attempt to start RabbitMQ twice, giving the RabbitMQ master node the necessary time to start after complete power loss. With the scripts in place, power up all nodes, then check to see whether the RabbitMQ server started on all nodes. All nodes should start automatically.</p>
<p>On the other hand, if the RabbitMQ master node has failed, the init script performs the following actions during the rabbitmq-server start. It moves the existing Mnesia database to a backup directory, and then makes the third and final attempt to start the RabbitMQ server.  In this case, RabbitMQ starts with a clean database, and the live rabbit nodes assemble a new cluster. The script uses the current RabbitMQ settings to find the current Mnesia location and creates a backup directory in the same path as Mnesia, tagged with the current date.</p>
<p>So with the customized init scripts included in Fuel 2.1, in most cases RabbitMQ simply starts after complete power loss and automatically assembles the cluster, but you can manage the process yourself.</p>
<p><strong>Background:</strong> See <a class="reference external" href="http://comments.gmane.org/gmane.comp.networking.rabbitmq.general/19792">http://comments.gmane.org/gmane.comp.networking.rabbitmq.general/19792</a>.</p>
</div>
<div class="section" id="id1">
<h3><a class="toc-backref" href="#id6">Galera cluster has no built-in restart or shutdown mechanism</a><a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p><strong>Issue:</strong>
A Galera cluster cannot be simply started or stopped. It is designed to work continuously.</p>
<p><strong>Workaround:</strong>
Galera, as high availability software, does not include any built-in full cluster shutdown or restart sequence. It is supposed to be running on a 24/7/365 basis. On the other hand, deploying, updating or restarting Galera may lead to different issues. This guide is intended to help avoid some of these issues. Regular Galera cluster startup includes a combination of the procedures described below. These procedures, with some differences, are performed by Fuel manifests.</p>
<p><strong>Stopping a single Galera node</strong>
There is no dedicated Galera process - Galera works inside the MySQL server process. The MySQL server should be patched with Galera WSREP patch to be able to work as Galera cluster.</p>
<p>All Galera stop steps listed below are automatically performed by the mysql init script supplied by Fuel installation manifests, so in most cases it should be enough to perform the first step only. In case even init script fails in some (rare, as we hope) circumstances, repeat step 2 manually.</p>
<ol class="arabic">
<li><dl class="first docutils">
<dt>Run <tt class="docutils literal"><span class="pre">service</span> <span class="pre">mysql</span> <span class="pre">stop</span></tt>.</dt>
<dd><p class="first last">Wait 15-30 seconds to ensure all MySQL processes are shut down.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Run <tt class="docutils literal"><span class="pre">ps</span> <span class="pre">-ef</span> <span class="pre">|</span> <span class="pre">grep</span> <span class="pre">mysql</span></tt> and stop ALL(!) <strong>mysqld</strong> and <strong>mysqld_safe</strong> processes.</dt>
<dd><ul class="first simple">
<li>Wait 20 seconds and run <tt class="docutils literal"><span class="pre">ps</span> <span class="pre">-ef</span> <span class="pre">|</span> <span class="pre">grep</span> <span class="pre">mysql</span></tt> again to see if any mysqld processes have restarted.</li>
<li>Stop or kill any new mysqld or mysqld_safe processes.</li>
</ul>
<p class="last">It is very important to stop all MySQL processes. Galera uses <tt class="docutils literal"><span class="pre">mysqld_safe</span></tt> and it may start additional MySQL processes. So even if you don&#8217;t immediately see any running processes, additional processes may be already starting.      That is why we check running processes twice. <tt class="docutils literal"><span class="pre">mysqld_safe</span></tt> has a default timeout 15 seconds before processes restart.  If, after that time, <tt class="docutils literal"><span class="pre">mysqld</span></tt> processes are running, the node may be considered shut down.</p>
</dd>
</dl>
</li>
</ol>
<p>If there was nothing to kill and all MySQL processes stopped after the <tt class="docutils literal"><span class="pre">service</span> <span class="pre">mysql</span> <span class="pre">stop</span></tt> command, the node may be considered shut down gracefully.</p>
<p><strong>Stop the Galera cluster</strong>
A Galera cluster is a master-master replication cluster. Therefore, it is always in the process of synchronization.</p>
<p>The recommended way to stop the cluster involves the following steps:</p>
<ol class="arabic">
<li><p class="first">Stop all requests to the cluster from outside.  Under heavy load, a default Galera non-synchronized cache may be up to 1 Gb; you may have to wait until every node is fully synced to shut the cluster down.</p>
</li>
<li><p class="first">Select the first node to shut down.  In general, it&#8217;s better to start with the non-primary nodes. Connect to this node with the mysql console.</p>
</li>
<li><p class="first">Run <tt class="docutils literal"><span class="pre">show</span> <span class="pre">status</span> <span class="pre">like</span> <span class="pre">'wsrep_local_state%';</span></tt></p>
<p>If it is &#8220;Synced&#8221;, then you may start the shutdown node procedure.</p>
<p>If the node is non-synchronized, you may still shut it down, but make sure you don&#8217;t start a new cluster operation from this node in the future.</p>
</li>
<li><p class="first">In mysql console, run the following command:</p>
<div class="highlight-python"><pre>SET GLOBAL wsrep_on='OFF';</pre>
</div>
<p>Replication stops immediately after the <tt class="docutils literal"><span class="pre">wsrep_on</span></tt> variable is set to &#8220;OFF&#8221;, so avoid making any changes to the node after this changing this setting.</p>
</li>
<li><p class="first">Exit from the mysql console.</p>
</li>
<li><p class="first">Follow the steps described in <cite>Stopping a single Galera node</cite> to stop the node altogether.</p>
</li>
</ol>
<p>Repeat these instructions for each remaining node in the cluster.</p>
<p>Remember which node you are going to shut down last &#8211; ideally, it should be the primary node in the synced state. This is the node you should start first when you decide to continue cluster operation.</p>
<p><strong>Starting Galera and creating a new cluster</strong>
Galera writes its state to file the file <tt class="docutils literal"><span class="pre">grastate.dat</span></tt>, residing in the location specified in the <tt class="docutils literal"><span class="pre">wsrep_data_home_dir</span></tt> variable.  This variable defaults to <tt class="docutils literal"><span class="pre">mysql_real_data_home</span></tt>, and Fuel OpenStack deployment manifests use this default location, creating the file at <tt class="docutils literal"><span class="pre">/var/lib/mysql/grastate.dat</span></tt>.</p>
<p>In the case of an unexpected cluster shutdown, this file can be useful for finding the node with the most recent commit. Simply compare the &#8220;UUID&#8221; values of <tt class="docutils literal"><span class="pre">grastat.dat</span></tt> from every node. The greater &#8220;UUID&#8221; value indicates which node has the latest commit.</p>
<p>If the cluster was shut down gracefully and last shut down node is known, simply perform the steps below to start up the cluster. Alternatively, you can find the node with the most recent commit using the <tt class="docutils literal"><span class="pre">grastat.dat</span></tt> files and start the cluster operation from that node.</p>
<ol class="arabic">
<li><p class="first">Ensure that all Galera nodes are shut down.</p>
<p>Any running nodes will be outside the new cluster untill restart, which could affect data integrity.</p>
</li>
<li><p class="first">Select the primary node.</p>
<p>This node is supposed to start first. It creates a new cluster ID and a new last commit UUID
(the <tt class="docutils literal"><span class="pre">wsrep_cluster_state_uuid</span></tt> variable represents this UUID inside the MySQL process).
Fuel deployment manifests with default settings set up <tt class="docutils literal"><span class="pre">fuel-controller-01</span></tt> to be both the primary Galera cluster node and the first deployed OpenStack controller.
* Open <tt class="docutils literal"><span class="pre">/etc/mysql/conf.d/wsrep.cnf</span></tt>
* Set  empty cluster address as follows (including quotation marks):</p>
<p><tt class="docutils literal"><span class="pre">wsrep_cluster_address=&quot;gcomm://&quot;</span></tt></p>
<ul class="simple">
<li>Save changes to the config file.</li>
</ul>
</li>
<li><p class="first">Run the <tt class="docutils literal"><span class="pre">service</span> <span class="pre">mysql</span> <span class="pre">start</span></tt> command on the first primary node or restart MySQL
if there were configuration changes to <tt class="docutils literal"><span class="pre">wsrep.cnf</span></tt>.</p>
<ul class="simple">
<li>Connect to MySQL server.</li>
<li>Run the <tt class="docutils literal"><span class="pre">SET</span> <span class="pre">GLOBAL</span> <span class="pre">wsrep_on='ON';</span></tt> to start replication within the new cluster. This variable can also be set by editing the <tt class="docutils literal"><span class="pre">wsrep.cnf</span></tt> file.</li>
<li>Check the new cluster status by running the following command: <tt class="docutils literal"><span class="pre">show</span> <span class="pre">status</span> <span class="pre">like</span> <span class="pre">'wsrep%';</span></tt><ul>
<li><tt class="docutils literal"><span class="pre">wsrep_local_state_comment</span></tt> should be &#8220;Synced&#8221;</li>
<li><tt class="docutils literal"><span class="pre">wsrep_cluster_status</span></tt> should be &#8220;Primary&#8221;</li>
<li><tt class="docutils literal"><span class="pre">wsrep_cluster_size</span></tt> should be &#8220;1&#8221;, as this is the only cluster that&#8217;s been started so far.</li>
<li><tt class="docutils literal"><span class="pre">wsrep_incoming_addresses</span></tt> should include only the address of the current node.</li>
</ul>
</li>
</ul>
</li>
<li><p class="first">Select one of the secondary nodes.</p>
<ul>
<li><p class="first">Check its <tt class="docutils literal"><span class="pre">/etc/mysql/conf.d/wsrep.cnf</span></tt> file.</p>
<ul>
<li><p class="first">The <tt class="docutils literal"><span class="pre">wsrep_cluster_address=&quot;gcomm://node1,node2&quot;</span></tt> variable should include the name or IP address
of the already started primary node. Otherwise, this node will definitely fail to start.</p>
<p><strong>Note.</strong>
<em>Due to a Galera bug, do not include a node&#8217;s own name and address in the ``wsrep_cluster_address`` specified for that node; while each Galera node attempts to exclude its own address, sometimes it fails.  In this case, the Galera node fails to start, with a &#8220;Cannot open channel...&#8221; error in</em> <strong>/etc/log/mysqld.log</strong></p>
<p>In the case of OpenStack deployed by Fuel manifests with default settings (2 controllers), Fuel automatically removes local names and IP addresses from gcomm strings on every node to prevent a node from attempting to connect to itself.  This parameter should look like this:</p>
<p><tt class="docutils literal"><span class="pre">wsrep_cluster_address=&quot;gcomm://fuel-controller-01:4567&quot;</span></tt></p>
</li>
</ul>
</li>
<li><p class="first">If <tt class="docutils literal"><span class="pre">wsrep_cluster_address</span></tt> is set correctly, run <tt class="docutils literal"><span class="pre">rm</span> <span class="pre">-f</span> <span class="pre">/var/lib/mysql/grastate.dat</span></tt> and then <tt class="docutils literal"><span class="pre">service</span> <span class="pre">mysql</span> <span class="pre">start</span></tt> on this node.</p>
</li>
</ul>
</li>
<li><p class="first">Connect to any node with mysql and run <tt class="docutils literal"><span class="pre">show</span> <span class="pre">status</span> <span class="pre">like</span> <span class="pre">'wsrep%';</span></tt> again.</p>
<ul class="simple">
<li><tt class="docutils literal"><span class="pre">wsrep_local_state_comment</span></tt> should finally change from &#8220;Donor/Synced&#8221; or other statuses to &#8220;Synced&#8221;.</li>
</ul>
<p>Time to sync may vary depending on the database size and connection speed.</p>
<ul class="simple">
<li><tt class="docutils literal"><span class="pre">wsrep_cluster_status</span></tt> should be &#8220;Primary&#8221; on both nodes.</li>
</ul>
<p>Galera is a master-master replication cluster and every node becomes primary by default (i.e. master).
Galera also supports master-slave configuration for special purposes.
Slave nodes have the &#8220;Non-Primary&#8221; value for <tt class="docutils literal"><span class="pre">wsrep_cluster_status</span></tt>.</p>
<ul class="simple">
<li><tt class="docutils literal"><span class="pre">wsrep_cluster_size</span></tt> should be &#8220;2&#8221;, since we have just added one more node to the cluster.</li>
<li><tt class="docutils literal"><span class="pre">wsrep_incoming_addresses</span></tt> should include the addresses of both started nodes.</li>
</ul>
<p><strong>Note:</strong>
State transfer is a heavy operation not only on the joining node, but also on the donor. In particular, the state donor may be not able to serve client requests, or it just plain may be slow.</p>
</li>
<li><p class="first">Repeat step 4 on all remaining controllers</p>
<p>If all secondary controllers are started successfully and became synced and you do not plan to restart the cluster in the near future, it is strongly recommended that you change the <tt class="docutils literal"><span class="pre">wsrep</span></tt> configuration settings on the first controller.</p>
<ul class="simple">
<li>Open file <tt class="docutils literal"><span class="pre">/etc/mysql/conf.d/wsrep.cnf</span></tt>.</li>
<li>Set <tt class="docutils literal"><span class="pre">wsrep_cluster_address=</span></tt> to the same value (node list) that is used for every secondary controller.</li>
</ul>
<p>In case of OpenStack deployed by Fuel manifests with default settings (2 controllers), on every operating controller this parameter should finally look like</p>
<p><tt class="docutils literal"><span class="pre">wsrep_cluster_address=&quot;gcomm://fuel-controller-01:4567,fuel-controller-02:4567&quot;</span></tt></p>
<p>This step is important for future failures or maintenance procedures. If the Galera primary controller node is restarted for any reason, if it has the empty &#8220;gcomm&#8221; value (i.e. <tt class="docutils literal"><span class="pre">wsrep_cluster_address=&quot;gcomm://&quot;</span></tt>), it creates a new cluster and exits the existing cluster. The existing cluster nodes may also stop receiving requests and the synchronization process to prevent data de-synchronization issues.</p>
</li>
</ol>
<p><strong>Note:</strong></p>
<p>Starting wtih mysql version 5.5.28_wsrep23.7 (Galera version 2.2), Galera cluster supports an additional start mode. Instead of setting <tt class="docutils literal"><span class="pre">wsrep_cluster_address=&quot;gcomm://&quot;</span></tt>, on the first node one can set the following URL for cluster address:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">wsrep_cluster_address</span><span class="o">=</span><span class="s">&quot;gcomm://node1,node2:port2,node3?pc.wait_prim=yes&quot;</span>
</pre></div>
</div>
<p>where <tt class="docutils literal"><span class="pre">nodeX</span></tt> is the name or IP address of one of available nodes, with optional port.</p>
<p>Therefore, every Galera node may have the same configuration file with the list of all nodes. It is designed to eliminate all configuration file changes on the first node after the cluster is started.</p>
<p>After the nodes are started, with mysql one may set the <tt class="docutils literal"><span class="pre">pc.bootstrap=1</span></tt> flag to the node which should start the new cluster and become the primary node. All other nodes should automatically perform initial synchronization with this new primary node. This flag may be also provided for a single selected node via the <tt class="docutils literal"><span class="pre">wsrep.cnf</span></tt> configuration file as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">wsrep_cluster_address</span><span class="o">=</span><span class="s">&quot;gcomm://node1,node2:port2,node3?pc.wait_prim=yes&amp;pc.bootstrap=1&quot;</span>
</pre></div>
</div>
<p>Unfortunately, due to a bug in the mysql init script (&lt;<a class="reference external" href="https://bugs.launchpad.net/codership-mysql/+bug/1087368">https://bugs.launchpad.net/codership-mysql/+bug/1087368</a>&gt;), the bootstrap flag is completely ignored in Galera 2.2 (wsrep_2.7). So, to start a new cluster, one should use the old way with an empty <tt class="docutils literal"><span class="pre">gcomm://</span></tt> URL. All other nodes may have both the single node and multiple node list in the <tt class="docutils literal"><span class="pre">gcomm</span></tt> URL, the bug affects only the first node - the one that starts the new cluster. Please note also that nodes with non-empty <tt class="docutils literal"><span class="pre">gcomm</span></tt> URL may start only if at least one of the nodes listed in <tt class="docutils literal"><span class="pre">gcomm://node1,node2:port2,node3</span></tt> is already started and is available for initial synchronization. For every starting Galera node it is enough to have at least one working node name/address to get full information about the cluster structure and to perform initial synchronization. Fuel deployment manifests with default settings may or may not set:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">wsrep_cluster_address</span><span class="o">=</span><span class="s">&quot;gcomm://&quot;</span>
</pre></div>
</div>
<p>on the primary node (first deployed OpenStack controller) and node list like:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">wsrep_cluster_address</span><span class="o">=</span><span class="s">&quot;gcomm://fuel-controller-01:4567,fuel-controller-02:4567&quot;</span>
</pre></div>
</div>
<p>on every secondary controller. Therefore, it is a good idea to check these parameters after the deployment is finished.</p>
<p><strong>Note:</strong></p>
<p>A Galera cluster is a very democratic system. As it is a master-master cluster, every primary node equals to other primary nodes. Primary nodes with the same sync state (same <tt class="docutils literal"><span class="pre">wsrep_cluster_state_uuid</span></tt> value) form the so called quorum - the majority of primary nodes with the same <tt class="docutils literal"><span class="pre">wsrep_cluster_state_uuid</span></tt>. Normally, one of the controllers gets a new commit, increases its <tt class="docutils literal"><span class="pre">wsrep_cluster_state_uuid</span></tt> value and performs synchronization with other nodes. If one of primary controllers fails, the Galera cluster continues serving requests as long as the quorum exists. Exit of the primary controller from the cluster equals a failure, because after exit this controller has a new cluster ID and a <tt class="docutils literal"><span class="pre">wsrep_cluster_state_uuid</span></tt> value less than the same value on the working nodes. So 3 working primary controllers are the very minimal Galera cluster size. The recommended Galera cluster size is 6 controllers.</p>
<p>Fuel deployment manifests with default settings deploy a non-recommended Galera configuration with 2 controllers only. This is suitable for testing purposes, but not for production deployments.</p>
<p><strong>Restarting an existing cluster after failure</strong></p>
<dl class="docutils">
<dt>Continuing a Galera cluster after a power failure or other types of breakdown basically consists of two steps:</dt>
<dd><ul class="first last simple">
<li>Backing up every node</li>
<li>Finding the node with the most recent non-damaged replica.</li>
</ul>
</dd>
</dl>
<ul class="simple">
<li>Helpful tip: add <tt class="docutils literal"><span class="pre">wsrep_provider_options=&quot;wsrep_on</span> <span class="pre">=</span> <span class="pre">off;&quot;</span></tt> to the <tt class="docutils literal"><span class="pre">/etc/mysql/conf.d/wsrep.cnf</span></tt> configuration file.</li>
</ul>
<p>After these steps simply perform the <strong>Start Galera and create a new cluster</strong> procedure,
starting from the node with the most recent non-damaged replica.</p>
</div>
<div class="section" id="id2">
<h3><a class="toc-backref" href="#id7">Useful links</a><a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Galera documentation from Galera authors:<ul>
<li><a class="reference external" href="http://www.codership.com/wiki/doku.php">http://www.codership.com/wiki/doku.php</a></li>
</ul>
</li>
<li>Actual Galera and WSREP patch bug list and official Galera/WSREP bug tracker:<ul>
<li><a class="reference external" href="https://launchpad.net/codership-mysql">https://launchpad.net/codership-mysql</a></li>
<li><a class="reference external" href="https://launchpad.net/galera">https://launchpad.net/galera</a></li>
</ul>
</li>
<li>One of recommended Galera cluster robust configurations:<ul>
<li><a class="reference external" href="http://wiki.vps.net/vps-net-features/cloud-servers/template-information/galeramysql-recommended-cluster-configuration/">http://wiki.vps.net/vps-net-features/cloud-servers/template-information/galeramysql-recommended-cluster-configuration/</a></li>
</ul>
</li>
<li>Why we use Galera:<ul>
<li><a class="reference external" href="http://openlife.cc/blogs/2011/july/ultimate-mysql-high-availability-solution">http://openlife.cc/blogs/2011/july/ultimate-mysql-high-availability-solution</a></li>
</ul>
</li>
<li>Other questions (seriously, sometimes there is not enough info about Galera available in the official Galera docs):<ul>
<li><a class="reference external" href="http://www.google.com">http://www.google.com</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="common-technical-issues">
<span id="id3"></span><h2><a class="toc-backref" href="#id8">Common Technical Issues</a><a class="headerlink" href="#common-technical-issues" title="Permalink to this headline">¶</a></h2>
<ol class="arabic">
<li><p class="first">Puppet fails with</p>
<div class="highlight-python"><pre>err: Could not retrieve catalog from remote server: Error 400 on SERVER: undefined method 'fact_merge' for nil:NilClass"</pre>
</div>
</li>
</ol>
<blockquote>
<div><ul class="simple">
<li>This is a Puppet bug.  See: <a class="reference external" href="http://projects.puppetlabs.com/issues/3234">http://projects.puppetlabs.com/issues/3234</a></li>
<li>Workaround: <tt class="docutils literal"><span class="pre">service</span> <span class="pre">puppetmaster</span> <span class="pre">restart</span></tt></li>
</ul>
</div></blockquote>
<ol class="arabic" start="2">
<li><p class="first">Puppet client will never resend the certificate to Puppet Master. The certificate cannot be signed and verified.</p>
<blockquote>
<div><ul>
<li><p class="first">This is a Puppet bug.  See: <a class="reference external" href="http://projects.puppetlabs.com/issues/4680">http://projects.puppetlabs.com/issues/4680</a></p>
</li>
<li><dl class="first docutils">
<dt>Workaround:</dt>
<dd><ul class="first last">
<li><p class="first">On Puppet client:</p>
<div class="highlight-python"><pre>rm -f /etc/puppet/ssl/certificate_requests/\*.pem
rm -f /etc/puppet/ssl/certs/\*.pem</pre>
</div>
</li>
<li><p class="first">On Puppet master:</p>
<div class="highlight-python"><pre>rm -f /var/lib/puppet/ssl/ca/requests/\*.pem</pre>
</div>
</li>
</ul>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">The manifests are up-to-date under <tt class="docutils literal"><span class="pre">/etc/puppet/manifests</span></tt>, but Puppet master keeps serving the previous version of manifests to the clients. Manifests seem to be cached by the Puppet Master.</p>
<blockquote>
<div><ul class="simple">
<li>More information: <a class="reference external" href="https://groups.google.com/forum/?fromgroups=#!topic/puppet-users/OpCBjV1nR2M">https://groups.google.com/forum/?fromgroups=#!topic/puppet-users/OpCBjV1nR2M</a></li>
<li>Workaround: <tt class="docutils literal"><span class="pre">service</span> <span class="pre">puppetmaster</span> <span class="pre">restart</span></tt></li>
</ul>
</div></blockquote>
</li>
<li><p class="first">Timeout error for fuel-controller-XX when running <tt class="docutils literal"><span class="pre">puppet-agent</span> <span class="pre">--test</span></tt> to install OpenStack when using HDD instead of SSD</p>
<div class="highlight-python"><pre>| Sep 26 17:56:15 fuel-controller-02 puppet-agent[1493]: Could not retrieve catalog from remote server: execution expired
| Sep 26 17:56:15 fuel-controller-02 puppet-agent[1493]: Not using cache on failed catalog
| Sep 26 17:56:15 fuel-controller-02 puppet-agent[1493]: Could not retrieve catalog; skipping run</pre>
</div>
<ul>
<li><dl class="first docutils">
<dt>Workaround: <tt class="docutils literal"><span class="pre">vi</span> <span class="pre">/etc/puppet/puppet.conf</span></tt></dt>
<dd><ul class="first last simple">
<li>add: <tt class="docutils literal"><span class="pre">configtimeout</span> <span class="pre">=</span> <span class="pre">1200</span></tt></li>
</ul>
</dd>
</dl>
</li>
</ul>
</li>
<li><p class="first">On running &#8220;<tt class="docutils literal"><span class="pre">puppet</span> <span class="pre">agent</span> <span class="pre">--test</span></tt>&#8221;, the error messages below occur:</p>
<div class="highlight-python"><pre>| err: /File[/var/lib/puppet/lib]: Could not evaluate: Could not retrieve information from environment production source(s) puppet://fuel-pm.localdomain/plugins</pre>
</div>
<ul class="simple">
<li>Workaround: <a class="reference external" href="http://projects.reductivelabs.com/issues/2244">http://projects.reductivelabs.com/issues/2244</a></li>
</ul>
<blockquote>
<div><p>and</p>
<div class="highlight-python"><pre>| err: Could not retrieve catalog from remote server: Error 400 on SERVER: stack level too deep
| warning: Not using cache on failed catalog
| err: Could not retrieve catalog; skipping run</pre>
</div>
<ul class="simple">
<li>Workaround: The second problem can be solved by rebooting Puppet master.</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">PuppetDB Connection Failures:</p>
<p>Puppet fails on fuel-pm with message:</p>
<div class="highlight-python"><pre>Could not retrieve catalog from remote server: Error 400 on SERVER: Failed to submit 'replace facts' command for fuel-pm to PuppetDB at fuel-pm:8081: Connection refused - connect(2)</pre>
</div>
</li>
</ol>
<blockquote>
<div><p>This message is often the result of one of the following:</p>
<ul>
<li><p class="first">Firewall blocking the puppetdb port</p>
</li>
<li><p class="first">DNS issues with the hostname specified in your puppetdb.conf</p>
</li>
<li><p class="first">DNS issues with the ssl-host specified in your jetty.ini on the puppetdb server</p>
</li>
<li><p class="first">Workaround: If you are able to connect (e.g. via telnet) to port 8081 on the puppetdb machine, puppetdb is running.  To try and isolate the problem, add the following to <tt class="docutils literal"><span class="pre">/etc/puppetdb/conf.d/jetty.ini</span></tt>:</p>
<div class="highlight-python"><pre>certificate-whitelist = /etc/puppetdb/whitelist.txt</pre>
</div>
</li>
</ul>
<blockquote>
<div>Be sure to list all aliases for the machine in that file.</div></blockquote>
</div></blockquote>
<div class="section" id="creating-the-xfs-partition">
<span id="create-the-xfs-partition"></span><h3><a class="toc-backref" href="#id9">Creating the XFS partition</a><a class="headerlink" href="#creating-the-xfs-partition" title="Permalink to this headline">¶</a></h3>
<p>In most cases, Fuel creates the XFS partition for you.  If for some reason you need to create it yourself, use this procedure:</p>
<ol class="arabic">
<li><p class="first">Create the partition itself:</p>
<div class="highlight-python"><pre>fdisk /dev/sdb
n(for new)
p(for partition)
&lt;enter&gt; (to accept the defaults)
&lt;enter&gt; (to accept the defaults)
w(to save changes)</pre>
</div>
</li>
<li><p class="first">Initialize the XFS partition:</p>
<div class="highlight-python"><pre>mkfs.xfs -i size=1024 -f /dev/sdb1</pre>
</div>
</li>
<li><p class="first">For a standard swift install, all data drives are mounted directly under /srv/node, so first create the mount point:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">mkdir</span> <span class="o">-</span><span class="n">p</span> <span class="o">/</span><span class="n">srv</span><span class="o">/</span><span class="n">node</span><span class="o">/</span><span class="n">sdb1</span>
</pre></div>
</div>
</li>
<li><p class="first">Finally, add the new partition to fstab so it mounts automatically, then mount all current partitions:</p>
<div class="highlight-python"><pre>echo "/dev/sdb1 /srv/node/sdb1 xfs
noatime,nodiratime,nobarrier,logbufs=8 0 0" &gt;&gt; /etc/fstab
mount -a</pre>
</div>
</li>
</ol>
</div>
<div class="section" id="redeploying-a-node-from-scratch">
<h3><a class="toc-backref" href="#id10">Redeploying a node from scratch</a><a class="headerlink" href="#redeploying-a-node-from-scratch" title="Permalink to this headline">¶</a></h3>
<p>Compute and Cinder nodes in an HA configuration and controller in any configuration cannot be redeployed without completely redeploying the cluster.  However, in a non-HA situation you can redeploy a compute or Cinder node.  To do so, follow these steps:</p>
<ol class="arabic simple">
<li>Remove the certificate for the node by executing the command <tt class="docutils literal"><span class="pre">puppet</span> <span class="pre">cert</span> <span class="pre">clean</span> <span class="pre">&lt;hostname&gt;</span></tt> on fuel-pm.</li>
<li>Re-boot the node over the network so it can be picked up by cobbler.</li>
<li>Run the puppet agent on the target node using <tt class="docutils literal"><span class="pre">puppet</span> <span class="pre">agent</span> <span class="pre">--test</span></tt>.</li>
</ol>
</div>
</div>
<div class="section" id="other-questions">
<h2><a class="toc-backref" href="#id11">Other Questions</a><a class="headerlink" href="#other-questions" title="Permalink to this headline">¶</a></h2>
<ol class="arabic">
<li><p class="first"><strong>[Q]</strong> Why did you decide to provide OpenStack packages through your own repository?</p>
<p><strong>[A]</strong> We are fully committed to providing our customers with working and stable bits and pieces in order to make successful OpenStack deployments. Please note that we do not distribute our own version of OpenStack; we rather provide a plain vanilla distribution. As such, there is no vendor lock-in. For convenience, our repository maintains the history of OpenStack packages certified to work with our Puppet manifests.</p>
<p>The advantage of this approach is that you can install any OpenStack version you want. If you are running Essex, just use the Puppet manifests which reference OpenStack packages for Essex from our repository. With each new release we add new OpenStack packages to our repository and created a separate branch with the Puppet manifests (which, in turn, reference these packages) corresponding to each release. With EPEL this would not be possible, as that repository only keeps the latest version for OpenStack packages.</p>
</li>
</ol>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="0055-production-considerations.html" title="Production Considerations"
             >previous</a> |</li>
        <li><a href="../index.html">Fuel for OpenStack 3.0 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2013, Mirantis.
      Last updated on 2013/07/22.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2b1.
    </div>
  </body>
</html>